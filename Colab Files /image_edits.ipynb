{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_edits.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8231ab_0dU3"
      },
      "source": [
        "# Rescale and edit training images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZcQcbFZOzxRW"
      },
      "source": [
        "### Fetch Dataset from Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htCJc1TQo_OK",
        "outputId": "95793902-7322-4976-e620-e44988fc6f30"
      },
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLnqSZrPJWwk"
      },
      "source": [
        "! unzip /content/drive/MyDrive/FYP_GAN/training.zip -d /content/training"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIdmc_o7z2Ov"
      },
      "source": [
        "###Â Clone StyleGAN2-ADA repository"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF3PYmbLzKX7"
      },
      "source": [
        "! git clone https://github.com/NVlabs/stylegan2-ada.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zKDTyN-z8PT"
      },
      "source": [
        "### Function to turn transparent pixels into white"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38eaBxpz3l9H"
      },
      "source": [
        "from PIL import Image"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WA5ZRDoQ3VYR"
      },
      "source": [
        "# Input image has to be a PIL object\n",
        "def whitenbg(img):\n",
        "  pixels = img.load()\n",
        "  img.convert(\"RGBA\")\n",
        "  if img.mode == \"RGBA\":\n",
        "    for j in range(img.size[1]): # rows\n",
        "      for i in range(img.size[0]): # columns\n",
        "      # Check if pixel is transparent\n",
        "        if pixels[i,j][3] < 255:\n",
        "          # Replace with white if transparent\n",
        "          pixels[i,j] = (255, 255, 255, 255)\n",
        "  return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5PAJG_103lB"
      },
      "source": [
        "### Function to resize images with respect to ratio"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8NF-8N6zON3"
      },
      "source": [
        "# Image has to be a PIL object\n",
        "def resize_img(img, width, height):\n",
        "\n",
        "  # Keep width and height ratios\n",
        "  width_ratio = width/img.width\n",
        "  height_ratio = height/img.height\n",
        "\n",
        "  # If the current height ratio is greater than the width ratio \n",
        "  if height_ratio > width_ratio:\n",
        "    new_width = width # Assign desired width to new_width\n",
        "    new_height = round(width_ratio * img.height) # Calculate new height with respect to width ratio\n",
        "  else:\n",
        "    new_height = height # Assign desired height to new_height\n",
        "    new_width = round(height_ratio * img.width) # Calculate new width with respect to height ratio\n",
        "\n",
        "  # Resize image using new sizes  \n",
        "  new_img = img.resize((new_width, new_height), Image.ANTIALIAS)\n",
        "\n",
        "  # Create new blank image with white background\n",
        "  resized_image = Image.new('RGBA', (width, height), \"WHITE\")\n",
        "\n",
        "  # Calculate image offset using by substracting the new sizes from the desired sizes\n",
        "  image_offset = (round((width - new_width)/2), round((height - new_height)/2))\n",
        "   \n",
        "  # Paste the new image along with its offset onto the blank canvas\n",
        "  resized_image.paste(new_img, image_offset)\n",
        "\n",
        "  return resized_image.convert('RGB')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOjXU0ep1LWq"
      },
      "source": [
        "### Apply defined functions on dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMzWHzIrOMXd"
      },
      "source": [
        "! mkdir /content/resized"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0NS_pSXMnmS"
      },
      "source": [
        "import os \n",
        "\n",
        "dir = \"/content/training\"\n",
        "count = 1\n",
        "for img in os.scandir(dir):\n",
        "  im = Image.open(img.path)\n",
        "  im = whitenbg(im)\n",
        "  new_im = resize_img(im, 256, 256)\n",
        "  new_im.save(\"/content/resized/img{}.jpg\".format(count))\n",
        "  print(\"changed \", count, \" images\")\n",
        "  count +=1\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IT_wpZ511fu"
      },
      "source": [
        "### Add dataset to Google Drive and Download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyyH6db-9d1s"
      },
      "source": [
        "!zip -r /content/resized.zip /content/resized/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFCwg4yILYm1"
      },
      "source": [
        "! cp /content/resized.zip /content/drive/MyDrive/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZkBk0x2N_6O"
      },
      "source": [
        "! ls /content/resized"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17IhBHYSPAoB"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/resized.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FowH531W2D9a"
      },
      "source": [
        "### Transform data into tfrecords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEJjn18k8Z33"
      },
      "source": [
        "!mkdir /content/tf_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWbOLDPQ8gWD",
        "outputId": "baf6f730-2b65-4676-dca4-9f134c385f4d"
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7iv4IJv24MN"
      },
      "source": [
        "!python /content/stylegan2-ada/dataset_tool.py create_from_images /content/tf_data/ /content/resized"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phzy71E39VYB"
      },
      "source": [
        "!zip -r /content/tf_data.zip /content/tf_data"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}